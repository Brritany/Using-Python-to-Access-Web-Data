{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOmY68Q8aSTACrgsNVwm2+k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brritany/Using-Python-to-Access-Web-Data/blob/main/%E5%9C%A8Google_Colab%E4%B8%8A%E4%BD%BF%E7%94%A8Python%E9%80%B2%E8%A1%8C%E7%B6%B2%E9%A0%81%E7%88%AC%E8%9F%B2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 在Google Colab上使用Python進行網頁爬蟲\n",
        "# Python Crawler in Google Colab\n",
        "___\n",
        "## Author\n",
        "> __Yong-Zhen, Huang__  \n",
        "m946111005@tmu.edu.tw  \n",
        "\n",
        "___\n"
      ],
      "metadata": {
        "id": "KXDLzB0p-980"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python package\n",
        "\n"
      ],
      "metadata": {
        "id": "pjuuiw56Nve2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BeautifulSoup"
      ],
      "metadata": {
        "id": "_YM-FMaYt99e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import\n",
        "\n",
        "```\n",
        "from bs4 import BeautifulSoup\n",
        "```"
      ],
      "metadata": {
        "id": "6Ozo2UxXO5r-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vdf4JctpNfhT"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html = \"\"\"\n",
        "<html><head><title>The Dormouse's story</title></head>\n",
        "<body>\n",
        "<p class=\"title\" name_\" dromouse\"><b>The Dormouse's story</b></p>\n",
        "<p class=\"story\">Once upon a time there were three little sisters; and their names were \n",
        "<a href=\"http://example.com/lacie\" class=\"sister\" id-\"link2\">Lacie</a> and\n",
        "<a href=\"http://example.com/tillie\" class=\"sister\" id-\"link3\">Tillie</a>;\n",
        "and they lived at the bottom of a well.</p>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(html, 'html.parser')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## find & find_all\n",
        "\n",
        "> `find` 只會抓取第一個標籤  \n",
        "> `find_all` 全部符合類型的標籤都會被抓取\n",
        "\n",
        "```\n",
        "#找出 body標籤，若有很多則只會拿到第一個\n",
        "print(soup.find(name = 'body'))\n",
        "\n",
        "#找出p標籤，若有很多則只會拿到第一個\n",
        "print(soup.find(name = 'p'))\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "_noXF3mJOkQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 找出 body標籤，若有很多則只會拿到第一個\n",
        "print(soup.find(name = 'body'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5zG1l-GUl8_",
        "outputId": "fe533969-e189-4bfc-b645-6f16b478d6f7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<body>\n",
            "<p class=\"title\" dromouse\"=\"\" name_\"=\"\"><b>The Dormouse's story</b></p>\n",
            "<p class=\"story\">Once upon a time there were three little sisters; and their names were \n",
            "<a class=\"sister\" href=\"http://example.com/lacie\" id-\"link2\"=\"\">Lacie</a> and\n",
            "<a class=\"sister\" href=\"http://example.com/tillie\" id-\"link3\"=\"\">Tillie</a>;\n",
            "and they lived at the bottom of a well.</p>\n",
            "</body>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 找出p標籤，若有很多則只會拿到第一個\n",
        "print(soup.find(name = 'p'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FI0xfNl_UqBI",
        "outputId": "22583a3c-2246-4b56-e840-27b2c1f1da8c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<p class=\"title\" dromouse\"=\"\" name_\"=\"\"><b>The Dormouse's story</b></p>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regular Expression (正規表示式)\n",
        "\n",
        "import  \n",
        "`import re`\n",
        "\n",
        "抓取標籤a或p  \n",
        "`(變數名 = re.compile(a|p`))\n",
        "\n",
        "\n",
        "```\n",
        "#以正規表示式，找出name中含有a或者是p的tag: \n",
        "import re\n",
        "tags = soup.find_all(name = re.compile('a|p'))\n",
        "for tag in tags:\n",
        "  print(tag)\n",
        "\n",
        "#以正規表示式，找出name 中含有a或者是p的tag，且class = 'title':\n",
        "tags = soup.find_all(name = re.compile('a|p'), attrs = {'class':'title'})\n",
        "for tag in tags:\n",
        "  print(tag)\n",
        "\n",
        "#以正規表示式，找出name中含有a或者是p的tag，且text = 'Lacie':\n",
        "tags = soup.find_all(name = re.compile('a|p'), text = 'Lacie')\n",
        "for tag in tags:\n",
        "  print(tag)\n",
        "\n",
        "#以正規表示式，找出name 中含有a或者是p的tag，且text = 'Lacie'or 'Tillie':\n",
        "tags = soup.find_all(name = re.compile('a|p'), text = ['Lacie','Tillie'])\n",
        "for tag in tags:\n",
        "  print(tag)\n",
        "```"
      ],
      "metadata": {
        "id": "WKEdxmxpRSx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "tags = soup.find_all(name = re.compile('a|p'))\n",
        "for tag in tags:\n",
        "  print(tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryPnyKdwUvaI",
        "outputId": "babb66af-e9b7-4ee9-90a7-be604ab016ce"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<head><title>The Dormouse's story</title></head>\n",
            "<p class=\"title\" dromouse\"=\"\" name_\"=\"\"><b>The Dormouse's story</b></p>\n",
            "<p class=\"story\">Once upon a time there were three little sisters; and their names were \n",
            "<a class=\"sister\" href=\"http://example.com/lacie\" id-\"link2\"=\"\">Lacie</a> and\n",
            "<a class=\"sister\" href=\"http://example.com/tillie\" id-\"link3\"=\"\">Tillie</a>;\n",
            "and they lived at the bottom of a well.</p>\n",
            "<a class=\"sister\" href=\"http://example.com/lacie\" id-\"link2\"=\"\">Lacie</a>\n",
            "<a class=\"sister\" href=\"http://example.com/tillie\" id-\"link3\"=\"\">Tillie</a>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 以正規表示式，找出name 中含有a或者是p的tag，且class = 'title':\n",
        "tags = soup.find_all(name = re.compile('a|p'), attrs = {'class':'title'})\n",
        "for tag in tags:\n",
        "  print(tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nBBE78KUzuO",
        "outputId": "5a5ecca7-d174-425b-842f-26869e955420"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<p class=\"title\" dromouse\"=\"\" name_\"=\"\"><b>The Dormouse's story</b></p>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 以正規表示式，找出name中含有a或者是p的tag，且text = 'Lacie':\n",
        "tags = soup.find_all(name = re.compile('a|p'), text = 'Lacie')\n",
        "for tag in tags:\n",
        "  print(tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiciZYTWUz2H",
        "outputId": "fac1bc7b-8b7f-4d9e-ae67-0d321a856888"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<a class=\"sister\" href=\"http://example.com/lacie\" id-\"link2\"=\"\">Lacie</a>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 以正規表示式，找出name 中含有a或者是p的tag，且text = 'Lacie'or 'Tillie':\n",
        "tags = soup.find_all(name = re.compile('a|p'), text = ['Lacie','Tillie'])\n",
        "for tag in tags:\n",
        "  print(tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2ms3YGwUz9M",
        "outputId": "7a45d785-18b7-42f9-d427-c170c2acfdb4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<a class=\"sister\" href=\"http://example.com/lacie\" id-\"link2\"=\"\">Lacie</a>\n",
            "<a class=\"sister\" href=\"http://example.com/tillie\" id-\"link3\"=\"\">Tillie</a>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## select\n",
        "\n",
        "```\n",
        "#選擇所有標籤p\n",
        "print(soup.select('p'))\n",
        "\n",
        "#選擇class為 title類型\n",
        "print(soup.select('.title'))\n",
        "\n",
        "#選擇id為 link2\n",
        "print(soup.select('#link2'))\n",
        "\n",
        "#選擇標籤名稱為a, id 為 link2的 tag\n",
        "print(soup.select('a#link2'))\n",
        "\n",
        "#從 body開始，在 body 裡找選擇有的p，且這些p的 tag 為a, id 為 link2 \n",
        "print(soup.select('body p a#link2'))\n",
        "```"
      ],
      "metadata": {
        "id": "flFs6G5YReM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(soup.select('p'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nocMUsQ5Qd23",
        "outputId": "6e524a52-cfac-4ea1-e2e6-f15973432319"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<p class=\"title\" dromouse\"=\"\" name_\"=\"\"><b>The Dormouse's story</b></p>, <p class=\"story\">Once upon a time there were three little sisters; and their names were \n",
            "<a class=\"sister\" href=\"http://example.com/lacie\" id-\"link2\"=\"\">Lacie</a> and\n",
            "<a class=\"sister\" href=\"http://example.com/tillie\" id-\"link3\"=\"\">Tillie</a>;\n",
            "and they lived at the bottom of a well.</p>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(soup.select('.title'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aF4fjRxVJD9",
        "outputId": "d1dfcdee-be2a-4874-c4c2-69fcfe713400"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<p class=\"title\" dromouse\"=\"\" name_\"=\"\"><b>The Dormouse's story</b></p>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <練習題1> \n",
        "\n",
        "爬取yahoo movie\n",
        "```\n",
        "url = 'https://movies.yahoo.com.tw/movie_thisweek.html'\n",
        "```"
      ],
      "metadata": {
        "id": "s-6thBM1VyQM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "訪問網站"
      ],
      "metadata": {
        "id": "QO_83YOMXC_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 訪問網站與解析網站建議分開寫，可避免多次爬取網站造成該網站誤認你在攻擊\n",
        "import requests\n",
        "\n",
        "url = 'https://movies.yahoo.com.tw/movie_thisweek.html'\n",
        "response = requests.get(url)\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iji4NdtSV5Qe",
        "outputId": "c9aca183-38c9-4ee3-aec9-dce8d955e4da"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# soup = BeautifulSoup(response.text, 'lxml') #寫法2 ?\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "info_items = soup.find_all('div', 'release_info')\n",
        "\n",
        "for item in info_items:\n",
        "  name = item.find('div', 'release_movie_name').a.text.strip()\n",
        "  en_name = item.find('div', 'en').a.text.strip()\n",
        "  release_time = item.find('div', 'release_movie_time').text.split(':')[-1].strip()\n",
        "  text = item.find('div', 'release_text').span.text.strip()\n",
        "\n",
        "  print(f'電影名稱：{name}{en_name}\\n{release_time}\\n介紹：\\n{text}')\n",
        "  print('------------------------')\n",
        "  print('\\n')"
      ],
      "metadata": {
        "id": "OrwVEW1YXLp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <練習題2>\n",
        "\n",
        "爬取PTT文章\n",
        "\n",
        "```\n",
        "url = 'https://ptt.cc/bbs/Gossiping/index.html'\n",
        "```"
      ],
      "metadata": {
        "id": "4Bl7AflCdXzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://www.ptt.cc/bbs/Gossiping/index.html'\n",
        "cookies = {'over18':'1'} #運用字典，填入查詢之名稱及值\n",
        "r = requests.get(url, cookies = cookies) #存入變數cookies\n",
        "r"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p42zZVLvhsxm",
        "outputId": "7c511c99-a1a1-4749-99a2-cbe1ea5d17d0"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "soup = BeautifulSoup(r.text, 'html.parser')\n",
        "\n",
        "ptt_posts = soup.find_all('div', {'class':'title'})\n",
        "\n",
        "for post in ptt_posts:\n",
        "  a_tag = post.find('a')\n",
        "  if a_tag is not None: #排除那些被刪除的文章\n",
        "    print(a_tag.text)\n",
        "    print('https://www.ptt.cc' + a_tag.get('href'))\n"
      ],
      "metadata": {
        "id": "Xptu981viFy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <練習題3>\n",
        "\n",
        "爬取PTT 作者、看版、標題、時間\n",
        "\n",
        "```\n",
        "url = 'https://www.ptt.cc/bbs/Gossiping/M.1664962579.A.35C.html'\n",
        "```"
      ],
      "metadata": {
        "id": "TFMbUy2esP9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://www.ptt.cc/bbs/Gossiping/M.1664962579.A.35C.html'\n",
        "cookies = {'over18':'1'} #運用字典，填入查詢之名稱及值\n",
        "r = requests.get(url, cookies = cookies) #存入變數cookies\n",
        "r"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neWcYVcgsWds",
        "outputId": "95c8e31d-7ded-4c3a-e8bb-b9d48d07166a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 方法一"
      ],
      "metadata": {
        "id": "a9mzKBU6t4gZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "soup = BeautifulSoup(r.text, 'html.parser')\n",
        "\n",
        "items = soup.find_all('span', {'class':'article-meta-value'})\n",
        "\n",
        "print('作者：', items[0].text)\n",
        "print('看板：', items[1].text)\n",
        "print('標題：', items[2].text)\n",
        "print('時間：', items[3].text)\n",
        "\n"
      ],
      "metadata": {
        "id": "-5nZTBtjsa-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 方法二"
      ],
      "metadata": {
        "id": "nChaWI4PuCvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "soup = BeautifulSoup(r.text, 'html.parser')\n",
        "\n",
        "items = soup.find_all('div', {'class':['article-metaline','article-metaline-right']})\n",
        "\n",
        "print(items[0].text)\n",
        "print(items[1].text)\n",
        "print(items[2].text)\n",
        "print(items[3].text)"
      ],
      "metadata": {
        "id": "STkwkCcEuCAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <練習題4>\n",
        "\n",
        "取得PTT 內文＆回文\n",
        "\n",
        "```\n",
        "url = 'https://www.ptt.cc/bbs/Gossiping/M.1664962579.A.35C.html'\n",
        "```"
      ],
      "metadata": {
        "id": "T8KttfqPjO-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://www.ptt.cc/bbs/Gossiping/M.1664962579.A.35C.html'\n",
        "cookies = {'over18':'1'} #運用字典，填入查詢之名稱及值\n",
        "r = requests.get(url, cookies = cookies) #存入變數cookies\n",
        "r"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECgRHWcIjg-u",
        "outputId": "67f2e842-11c9-4775-db27-27417fd6c4d8"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 取得內文\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "soup = BeautifulSoup(r.text, 'html.parser')\n",
        "\n",
        "all_text = soup.find('div', {'id': 'main-content'}).text\n",
        "\n",
        "# print(all_text) #會爬取到全部內容\n",
        "print(all_text[0:all_text.index('※ 發信站: 批踢踢實業坊(ptt.cc)')])"
      ],
      "metadata": {
        "id": "KzAF2j60jioJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 取得回文\n",
        "\n",
        "for push in soup.find_all('div', {'class': 'push'}):\n",
        "  sp = BeautifulSoup(push.text, 'html.parser')\n",
        "  items = sp.text.split(' ')\n",
        "\n",
        "  print('Tag: ', items[0])\n",
        "  print('ID: ', items[1])\n",
        "  print('comment', items[2])\n",
        "  print('time', items[3])\n",
        "  print('------------------')"
      ],
      "metadata": {
        "id": "-7QaP7TekbTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <練習題5>\n",
        "\n",
        "爬取多頁PTT的時間、網址、標題\n",
        "\n",
        "```\n",
        "url = 'https://www.ptt.cc/bbs/Food/index.html'\n",
        "```"
      ],
      "metadata": {
        "id": "BCJOfav7mlKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://www.ptt.cc/bbs/Food/index.html'\n",
        "\n",
        "for i in range(5): #想要爬取幾頁\n",
        "  print(f'第{i + 1}頁')\n",
        "  r = requests.get(url)\n",
        "  r.encoding = 'utf-8'\n",
        "  sp = BeautifulSoup(r.text, 'html.parser')\n",
        "  datas = sp.find_all('div', {'class': 'r-ent'})\n",
        "  for data in datas:\n",
        "    if data.a:\n",
        "      print(data.find('div', class_='date').text, end = ' ')\n",
        "      print('https://www.ptt.cc' + data.a.get('href'), end = ' ')\n",
        "      print(data.a.text)\n",
        "  url ='https://www.ptt.cc' + sp.find_all('a', class_='btn wide')[1].get('href') #進入下一頁網址\n"
      ],
      "metadata": {
        "id": "OUneOUxGmieP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <練習題6>\n",
        "\n",
        "goole search"
      ],
      "metadata": {
        "id": "E21pgxkhpH4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "google_url = 'https://www.google.com.tw/search'\n",
        "my_params = {'q': '寒流'} #輸入框參數為'q'，寒流則為我們要搜尋的關鍵字\n",
        "q_result = requests.get(google_url, params = my_params)\n",
        "\n",
        "if q_result.status_code == requests.codes.ok:\n",
        "  soup = BeautifulSoup(q_result.text, 'html.parser')\n",
        "  items = soup.select('a[href^=\"/url?q=\"]')\n",
        "\n",
        "  for i in items:\n",
        "    print('Title:' + i.text)\n",
        "    print('Web URL:' + i.get('href')[7:])"
      ],
      "metadata": {
        "id": "SHEa_eq0pNAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# selenium"
      ],
      "metadata": {
        "id": "ssfFBiHkt8PE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "install selenium in colab\n",
        "\n",
        "```\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium\n",
        "```"
      ],
      "metadata": {
        "id": "DFjZRNQFuOW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium"
      ],
      "metadata": {
        "id": "nk6G9H97uVxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome('chromedriver',options=options)\n",
        "driver.implicitly_wait(10)"
      ],
      "metadata": {
        "id": "uwiVfO_rxdcX"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "driver.get(\"https://google.com\")\n",
        "\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "q = driver.find_element(By.NAME, 'q') #輸入bar\n",
        "q.send_keys('寒流') #要搜尋的關鍵字\n",
        "q.submit() #送出搜尋"
      ],
      "metadata": {
        "id": "5Wf_q44Axowz"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs = driver.find_elements(By.CLASS_NAME, 'g')\n",
        "\n",
        "for g in gs:\n",
        "  print(g.text)"
      ],
      "metadata": {
        "id": "iD5AfDyJx9wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# combine BeautifulSoup & selenium"
      ],
      "metadata": {
        "id": "VFOIMcbnzOUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver \n",
        "import time\n",
        "import unittest\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "driver = webdriver.Chrome('chromedriver',options=options)\n",
        "driver.get('https://google.com')\n",
        "element = driver.find_element(By.NAME, 'q')\n",
        "element.send_keys('寒流')\n",
        "element.submit()\n",
        "\n",
        "time.sleep(1) #城市休息1秒鐘，等網頁出現\n",
        "html = driver.page_source\n",
        "soup = BeautifulSoup (html, \"html.parser\")\n",
        "items = soup.find_all('div', class_='yuRUbf')\n",
        "\n",
        "for i in items:\n",
        "  print(\"網址:\" + i.find('a')[ 'href'])\n",
        "  print(\"標題:\" + i.select('h3')[0].text)\n",
        "  print('\\n')\n",
        "\n",
        "driver.quit()"
      ],
      "metadata": {
        "id": "Ph85wOSSzWuc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}